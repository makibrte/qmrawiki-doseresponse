{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Output for Exp. 183\n",
      "['Dose', 'Infected', 'Non-infected', 'Total']\n",
      "   Dose Infected Non-infected Total\n",
      "0   100        2            2     4\n",
      "1   300        2            3     5\n",
      "2  1000        1            2     3\n",
      "3  3000        3            1     4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# The target URL\n",
    "url = 'https://qmrawiki.org/node/402'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find elements by HTML tags, attributes, or CSS class\n",
    "    titles = soup.find_all('h1')\n",
    "    for title in titles:\n",
    "        print(title.get_text())\n",
    "    tables_data = soup.find_all('table')\n",
    "    \n",
    "    for table_data in tables_data[3]:\n",
    "        table_row_data = [row for row in table_data.get_text().split('\\n') if row != '']\n",
    "        if len(table_row_data):\n",
    "            columns = table_row_data[1:5]\n",
    "            experiment_data = []\n",
    "            print(columns)\n",
    "            i = 5\n",
    "            while i <= len(table_row_data):\n",
    "                experiment_data\n",
    "                row_data = table_row_data[i:i+4]\n",
    "                i+=4 \n",
    "                if(len(row_data) > 0):\n",
    "                    experiment_data.append(row_data)\n",
    "    df = pd.DataFrame(columns=columns, data=experiment_data)\n",
    "    print(df)         \n",
    "else:\n",
    "    print('Failed to retrieve the webpage')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n108', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oral', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '8', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Iowa', 'strain', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oocysts', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'human', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'exponential', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n\\nk', '=', '4.19E-03\\nLD50/ID50', '=', '1.65E+02', '\\n', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'infection', '', '', '', '', '', '', '', '', '', '', '', '\\n\\nDuPont,', 'H', 'L.,', 'et', 'al.', '\"The', 'infectivity', 'of', 'Cryptosporidium', 'parvum', 'in', 'healthy', 'volunteers.\"', 'The', 'New', 'England', 'journal', 'of', 'medicine.', '332', '(1995):', '13.', '\\n']\n",
      "['\\n\\n139', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oral', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '8', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Iowa', 'isolate', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oocysts', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'human', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'exponential', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n\\nk', '=', '5.26E-03\\nLD50/ID50', '=', '1.32E+02', '\\n', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'infection', '', '', '', '', '', '', '', '', '', '', '', '\\n\\nMessner,', 'M', 'J.,', 'C', 'L.', 'Chappell,', 'and', 'P', 'C.', 'Okhuysen.', '\"Risk', 'Assessment', 'for', 'Cryptosporidium:', 'A', 'Hierarchical', 'Bayesian', 'Analysis', 'of', 'Human', 'Dose', 'Response', 'Data.\"', 'Water', 'Research.', '35', '(2001):', '16.', '\\n']\n",
      "['\\n\\n140', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oral', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '4', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'TAMU', 'isolate', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oocysts', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'human', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'exponential', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n\\nk', '=', '5.72E-02\\nLD50/ID50', '=', '1.21E+01', '\\n', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'infection', '', '', '', '', '', '', '', '', '', '', '', '\\n\\nMessner,', 'M', 'J.,', 'C', 'L.', 'Chappell,', 'and', 'P', 'C.', 'Okhuysen.', '\"Risk', 'Assessment', 'for', 'Cryptosporidium:', 'A', 'Hierarchical', 'Bayesian', 'Analysis', 'of', 'Human', 'Dose', 'Response', 'Data.\"', 'Water', 'Research.', '35', '(2001):', '16.', '\\n']\n",
      "['\\n\\n141', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oral', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '4', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'UCP', 'isolate', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oocysts', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'human', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'beta-Poisson', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '=', '1.45E-01\\n\\nLD50/ID50', '=', '1.79E+02', '\\nN50', '=', '1.79E+02', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'infection', '', '', '', '', '', '', '', '', '', '', '', '\\n\\nCoster,', 'T', 'S.,', 'et', 'al.', '\"Immune', 'response,', 'ciprofloxacin', 'activity,', 'and', 'gender', 'differences', 'after', 'human', 'experimental', 'challenge', 'by', 'two', 'strains', 'of', 'enterotoxigenic', 'Escherichia', 'coli.\"', 'Infection', 'and', 'immunity.', '75', '(2007):', '1.', '\\n']\n",
      "['\\n\\n181', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oral', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '4', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '*C.', 'hominis*,', 'TU502', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oocysts', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'human', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'beta-Poisson', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '=', '2.7E-01\\n\\nLD50/ID50', '=', '1.68E+01', '\\nN50', '=', '1.68E+01', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'diarrhea', '', '', '', '', '', '', '', '', '', '', '', '\\n\\nOkhuysen,', 'P', 'C.,', 'et', 'al.', '\"Infectivity', 'of', 'a', 'Cryptosporidium', 'parvum', 'Isolate', 'of', 'Cervine', 'Origin', 'for', 'Healthy', 'Adults', 'and', 'Interferon-Î³', 'Knockout', 'Mice.\"', 'Journal', 'of', 'Infectious', 'Diseases.', '185', '(2002):', '9.', '\\n']\n",
      "['\\n\\n183', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oral', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '4', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Moredun', 'isolate', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'oocysts', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'human', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'beta-Poisson', '', '', '', '', '', '', '', '', '', '', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '=', '1.14E-01\\n\\nLD50/ID50', '=', '4.55E+02', '\\nN50', '=', '4.55E+02', '', '\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', 'infection', '', '', '', '', '', '', '', '', '', '', '', '\\n\\nBlaser,', 'M', 'J.,', 'et', 'al.', '\"Experimental', 'Campylobacter', 'jejuni', 'Infection', 'of', 'Adult', 'Mice.\"', 'Infection', 'and', 'Immunity.', '39', '(1983):', '2.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "url_new = 'https://qmrawiki.org/experiments/cryptosporidium-parvum'\n",
    "\n",
    "response = requests.get(url_new)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    experiments_container = soup.find(class_='view-pathogen-dose-response-experiments')\n",
    "    \n",
    "    #experiments = experiments_container.find_all(class_='response-table-inner')\n",
    "\n",
    "    #for experiment in experiments:\n",
    "        #print(experiment.get_text().split(' '))\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1, iterating over all the dose response pages and going to next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_responses_url = 'https://qmrawiki.org/framework/dose-response/experiments'\n",
    "response = requests.get(dose_responses_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/node/1787\n",
      "Dose response has inline dataset\n",
      "<tr class=\"even\"><td class=\"row_2 col_0\">100</td><td class=\"row_2 col_1\">0</td><td class=\"row_2 col_2\">16</td><td class=\"row_2 col_3\">16</td> </tr>\n",
      "<tr class=\"even\"><td class=\"row_4 col_0\">10000</td><td class=\"row_4 col_1\">5</td><td class=\"row_4 col_2\">3</td><td class=\"row_4 col_3\">8</td> </tr>\n",
      "<td class=\"row_1 col_0\">10</td>\n",
      "<td class=\"row_1 col_1\">0</td>\n",
      "<td class=\"row_1 col_2\">8</td>\n",
      "<td class=\"row_1 col_3\">8</td>\n",
      "<td class=\"row_3 col_0\">1000</td>\n",
      "<td class=\"row_3 col_1\">2</td>\n",
      "<td class=\"row_3 col_2\">16</td>\n",
      "<td class=\"row_3 col_3\">18</td>\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "individual_dose_responses_list = soup.find(class_='quicktabs-views-group')\n",
    "\n",
    "dose_response_url = individual_dose_responses_list.find_all('span')\n",
    "base_url = 'https://qmrawiki.org'\n",
    "for dose_responses in dose_response_url:\n",
    "    temps = dose_responses.find_all('a')\n",
    "    for temp in temps:\n",
    "        experiment_overview_url = temp.get('href')\n",
    "        extract_from_dose_response_page(base_url+experiment_overview_url, base_url)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Have to adjust for pages that have the experiment data inside Experiment Dataset\n",
    "def extract_from_dose_response_page(url, base_url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        experiments_container = soup.select('td.views-field-field-experiment-id-text')\n",
    "        \n",
    "        for container in experiments_container:\n",
    "            experiment_url = container.find('a').get('href')\n",
    "            print(experiment_url)            \n",
    "            extract_from_experiment_page(base_url + experiment_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_experiment_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        experiment_dataset = soup.find_all(id='tablefield-0')\n",
    "\n",
    "        for data in experiment_dataset:\n",
    "            experiment_data_table = data.find_all('tr')\n",
    "            if(len(experiment_data_table) > 0):\n",
    "                print('Dose response has inline dataset')\n",
    "                parse_meta_table(experiment_data_table, response.text)\n",
    "                #TODO: Add function here to extract the data if the dataset is embeded\n",
    "            else:\n",
    "                experiment_data_html = extract_html_table(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_meta_table(data, page_txt):\n",
    "    i = 0\n",
    "    soup = BeautifulSoup(page_txt, 'html.parser')\n",
    "    odds = soup.select('tr.odd')    \n",
    "    evens = soup.select('tr.even')\n",
    "    columns = soup.select('th.row_0')\n",
    "    column_names = [column.get_text() for column in columns]\n",
    "    rows = []\n",
    "    even_counter = 2\n",
    "    odd_counter = 1\n",
    "    for even in evens:\n",
    "        \n",
    "        row = []\n",
    "        for n in even.find_all(class_=f'row_{even_counter}'):\n",
    "    \n",
    "            row.append(n.get_text())\n",
    "        even_counter += 2\n",
    "        rows.append(row)\n",
    "    for odd in odds:\n",
    "        row = []\n",
    "        \n",
    "        for n in odd.find_all(class_=f'row_{odd_counter}'):\n",
    "            \n",
    "            row.append(n.get_text())\n",
    "        rows.append(row)     \n",
    "        odd_counter += 2\n",
    "    df = pd.DataFrame(columns=column_names, data=rows) \n",
    "    print(df.shape)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikiparser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
